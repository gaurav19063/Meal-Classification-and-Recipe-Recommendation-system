{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification_auxiliary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShGl5-G6iVA8"
      },
      "source": [
        "# **Auxiliary Python code for classification task**\n",
        "\n",
        "### Includes preprocessing lookup ingredients\n",
        "### Generates TF-IDF vectorized ingredients\n",
        "### Saves the X features and Y corresponding labels\n",
        "### Trains svm on whole dataset and save it to be used for classify a new recipe "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aObHj0feA4AL"
      },
      "source": [
        "***Created by Rahul Maheshwari***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKEtqiRFXzoO"
      },
      "source": [
        "# all imports\n",
        "import re\n",
        "import pandas as pd\n",
        "from joblib import dump\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-qDhlv_iE4V"
      },
      "source": [
        "# for lemmatizing ingredients\n",
        "lm = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltxoZzKWiLFD"
      },
      "source": [
        "# load dataset and drop non-contributing columns\n",
        "df = pd.read_csv(\"recipes.csv\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = df.drop(['Recipe ID', 'Title', 'URL', 'Rating', 'Serves', 'Ingredients', 'Cooking instructions', 'Rating Score'],\n",
        "             axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7Q40rSCj2Fq"
      },
      "source": [
        "**Perform pre-processing on features and Vectorizing features (ingredients)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWFzzWyqiMtL"
      },
      "source": [
        "new = []\n",
        "for ing in df['Lookup Ingredients']:\n",
        "    ingredient = ing[1:-1]\n",
        "    ingredients = re.sub(r'[^\\w\\s]', '', ingredient).split(' ')\n",
        "    ingredient = ' '.join(ingredients)\n",
        "    new.append(ingredient)\n",
        "df['new_ingredients'] = new\n",
        "l = []\n",
        "for s in df['new_ingredients']:\n",
        "    words = word_tokenize(s)\n",
        "    word_ps = []\n",
        "    for w in words:\n",
        "        word_ps.append(lm.lemmatize(w))\n",
        "    s = ' '.join(word_ps)\n",
        "    l.append(s)\n",
        "df['modified_ingredients'] = l\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['modified_ingredients'])\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df['Meal'])\n",
        "df['Meal'] = le.transform(df['Meal'])\n",
        "Y = df['Meal']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rsB-9V1kDxz"
      },
      "source": [
        "**Save X and Y arrays to be used in the GUI for training and evaluation of various models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPwdLNO0iP37"
      },
      "source": [
        "np.save(\"X_array\", X)\n",
        "pickle_file = open('Y_array', 'wb')\n",
        "pickle.dump(Y, pickle_file)\n",
        "pickle_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7UPVSPBkLXS"
      },
      "source": [
        "**Training the model and saving for using it in GUI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhH5I2kviSXK"
      },
      "source": [
        "meal_map = {0: 'Breakfast', 1: 'Lunch', 2: 'Dinner'}\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "svm = SVC(C=20, kernel='rbf', gamma=1)\n",
        "svm.fit(X, Y)\n",
        "dump(svm, 'svm_model.joblib')\n",
        "ingredients = input(\"Enter ing\").split(',')\n",
        "ingredients = [i.strip() for i in ingredients]\n",
        "test_input = vectorizer.transform(ingredients)\n",
        "\n",
        "y_pred = svm.predict(test_input)\n",
        "# svm_accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "# print(svm_accuracy)\n",
        "# print(meal_map[y_pred[0]])\n",
        "print(meal_map[y_pred[0]])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}